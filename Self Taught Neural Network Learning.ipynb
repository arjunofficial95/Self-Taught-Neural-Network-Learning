{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below cell is directly taken from code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "options(warn=-1)\n",
    "library(h2o)\n",
    "#If there is a proxy: proxy.old <- Sys.getenv('http_proxy'); Sys.setenv('http_proxy'='');\n",
    "localH2O =  h2o.init(nthreads = -1, port = 54321, max_mem_size = '6G', startH2O = TRUE)\n",
    "\n",
    "\n",
    "# Students: Use the \"absolute\" path to the datasets on your machine (important)\n",
    "labeled.frame <- h2o.importFile(path = 'Task2C_labeled.csv' ,sep=',') \n",
    "unlabeled.frame <- h2o.importFile(path = 'Task2C_unlabeled.csv' ,sep=',') \n",
    "test.frame <- h2o.importFile(path = 'Task2C_test.csv' ,sep=',') \n",
    "\n",
    "labeled.frame[,1] <- as.factor(labeled.frame$label)\n",
    "unlabeled.frame[,1] <- NA\n",
    "train.frame <- h2o.rbind(labeled.frame[,-1], unlabeled.frame[,-1])\n",
    "test.frame[,1] <- as.factor(test.frame$label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# libraries\n",
    "library(reshape2)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "error function from code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "####################### GENERAL AUXILIARY FUNCTIONS #######################\n",
    "## The following structure helps us to have functions with multiple outputs\n",
    "### credit: https://stat.ethz.ch/pipermail/r-help/2004-June/053343.html\n",
    "\n",
    "error.rate <- function(Y1, T1){\n",
    "  if (nrow(Y1)!=nrow(T1)){\n",
    "    stop('error.rate: size of true lables and predicted labels mismatch')\n",
    "  }\n",
    "  return (sum(T1!=Y1)/nrow(T1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This below cell is my code implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# variables initialisation for storing the required data\n",
    "error<- 0\n",
    "reconstruction_error<- NULL\n",
    "classification_error <- NULL\n",
    "augmented_error <- NULL\n",
    "K<- NULL\n",
    "\n",
    "# for each K value\n",
    "for (k in seq(20, 400, 20)){\n",
    "  # appending the K value to a list\n",
    "  K <- append(K,k)\n",
    "\n",
    "  ############ reconstruction error (PART 1) ############################################\n",
    "  NN.model <- h2o.deeplearning(    \n",
    "    x = 2:ncol(train.frame), # select all pixels + extra features\n",
    "    training_frame = train.frame, # specify the frame (imported file)    \n",
    "    hidden = c(k), # number of layers and their units\n",
    "    epochs = 50, # maximum number of epoches  \n",
    "    activation = 'Tanh', # activation function \n",
    "    autoencoder = TRUE, # is it an autoencoder? Yes!\n",
    "    l2 = 0.1)\n",
    "    \n",
    "    # using the h2o.anomaly function to find the difference \n",
    "    # between original and estimated output and keeping per_feature=FALSE\n",
    "    anomaly<-h2o.anomaly(NN.model, train.frame, per_feature=FALSE)\n",
    "    # finding the mean of the anomaly\n",
    "    error <- mean(anomaly)\n",
    "    # storing the average reconstruction error in a list\n",
    "    reconstruction_error <- append(reconstruction_error,error)\n",
    "  \n",
    "    \n",
    "  ############# classification error (PART 2) ###########################################\n",
    "  NN.model.classification <- h2o.deeplearning(    \n",
    "     x = 2:ncol(labeled.frame), # select all pixels + extra features\n",
    "     y = 1,\n",
    "     training_frame = labeled.frame, # specify the frame (imported file)    \n",
    "     hidden = c(k), # number of layers and their units\n",
    "     epochs = 50, # maximum number of epoches  \n",
    "     activation = 'Tanh', # activation function \n",
    "     autoencoder = FALSE, \n",
    "     l2 = 0.1)\n",
    "    \n",
    "    # using the h2o.predict function to estimate the output\n",
    "    test.predict <- h2o.predict(NN.model.classification, test.frame)$predict\n",
    "    # using the error function to calculate the misclassification errors\n",
    "    classification.error <- error.rate(test.predict,test.frame$label)\n",
    "    # storing the misclassification errors in a list\n",
    "    classification_error <- append(classification_error, classification.error)\n",
    "    \n",
    "  \n",
    "  ################ augmented (PART 3) ###################################################\n",
    "  NN.model.labelled <- h2o.deeplearning(    \n",
    "    x = 2:ncol(labeled.frame), # select all pixels + extra features\n",
    "    training_frame = labeled.frame, # specify the frame (imported file)    \n",
    "    hidden = c(k), # number of layers and their units\n",
    "    epochs = 50, # maximum number of epoches  \n",
    "    activation = 'Tanh', # activation function \n",
    "    autoencoder = TRUE, # is it an autoencoder? Yes!\n",
    "    l2 = 0.1)\n",
    "    # from autoencoder getting the output\n",
    "    project.layer = as.matrix(h2o.deepfeatures(NN.model.labelled, labeled.frame, layer=1))\n",
    "    # original + extra feature from autoencoder\n",
    "    extra.feature <- h2o.cbind(labeled.frame, as.h2o(project.layer))\n",
    "  \n",
    "  # 3-layer NN with original + extra feature from autoencoder\n",
    "  NN.model.augmented <- h2o.deeplearning(    \n",
    "    x = 2:ncol(extra.feature), # select all pixels + extra features\n",
    "    y=1,\n",
    "    training_frame = extra.feature, # specify the frame (imported file)    \n",
    "    hidden = c(k), # number of layers and their units\n",
    "    epochs = 50, # maximum number of epoches  \n",
    "    activation = 'Tanh', # activation function \n",
    "    autoencoder = FALSE, # is it an autoencoder? Yes!\n",
    "    l2 = 0.1)\n",
    "    \n",
    "    # using the h2o.predict function to estimate the output\n",
    "    predict.test <- h2o.predict(NN.model.augmented, test.frame)$predict\n",
    "    # using the error function to calculate the misclassification errors\n",
    "    classification.error2 <- error.rate(predict.test,test.frame$label)\n",
    "    # storing the misclassification errors in a list\n",
    "    augmented_error <- append(augmented_error,classification.error2)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plotting for II. and VI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# PLOT 1\n",
    "######################### reconstruction error vs middle hidden layer error ##################################\n",
    "\n",
    "# building the dataframe and storing the k value along with the three errors we got above\n",
    "error.data <- data.frame(K, reconstruction_error, classification_error, augmented_error)\n",
    "# if you want to save the below plot then uncomment the below code which are in comment state now\n",
    "#pdf(file = \"reconstruction error vs middle hidden layer Question 3 III\")\n",
    "ggplot(data = error.data, aes(x= K, y= reconstruction_error)) + geom_line() + ggtitle('reconstruction error vs middle hidden layer error')\n",
    "#dev.off()\n",
    "\n",
    "\n",
    "\n",
    "# PLOT 2\n",
    "######################### 3 layer error vs augmented error #####################################################\n",
    "\n",
    "# creating a dataframe from the lists created in the for loop in the above cell\n",
    "error.plot <- data.frame(K, classification_error, augmented_error)\n",
    "# using reshape for ggplot\n",
    "error.plot.data <- melt(error.plot, id='K') \n",
    "# column renaming\n",
    "names(error.plot.data) <- c('K', 'Type',  'Error') \n",
    "# pdf(file = \"3 layer error vs augmented error Question 3 VI\")\n",
    "# plotting the 3 layer error vs augmented error for different layers\n",
    "ggplot(data = error.plot.data, aes(x= K, y= Error, color= Type)) + geom_line() + ggtitle(\"3 layer error vs augmented error\")\n",
    "# dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The objective of Autoencoder is reconstruction error minimisation between input/output, helping in learning key features found in data. Lesser the reconstruction error more will be the retention of information found in input.\n",
    "As per the plot, if the number of hidden layers is restricted to 200-250 we can retain as much information as possible from the input data, as we can see the error is rising sharply after 200-250. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (system-wide)",
   "language": "r",
   "metadata": {
    "cocalc": {
     "description": "R statistical programming language",
     "priority": 10,
     "url": "https://www.r-project.org/"
    }
   },
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}